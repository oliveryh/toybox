{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = 'watch-history.json'\n",
    "with open(file, encoding='utf8') as wh_file:\n",
    "    wh_dict = json.load(wh_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert json to dataframe\n",
    "wh = pd.DataFrame.from_dict(wh_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns except title and time\n",
    "wh = wh[['title', 'time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove \"Watched\" from title\n",
    "import string\n",
    "wh['title'] = wh['title'].apply(lambda x: x[7:])\n",
    "wh['title'] = wh['title'].apply(lambda x: x.lower())\n",
    "wh = wh.drop(wh[wh['title'].str.startswith('https://www.youtube.com')].index)\n",
    "wh['title'] = wh['title'].apply(lambda x: x.strip())\n",
    "wh['title'] = wh['title'].apply(lambda x: x.translate(str.maketrans(' ', ' ', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove deleted videos\n",
    "wh = wh.drop(wh[wh['title'].str.startswith('HTTPS://WWW.YOUTUBE.COM')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Oliver\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    if n > 1:\n",
    "        return zip(*(input_list[i:] for i in range(n)))\n",
    "    else:\n",
    "        return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wh['unigrams'] = wh['title'].apply(lambda x: [word for word in x.split(' ') if word not in stop_words])\n",
    "wh['unigrams'] = wh['unigrams'].apply(lambda x: [word for word in x if word != ''])\n",
    "wh['bigrams'] = wh['unigrams'].apply(lambda x: list(find_ngrams(x, 2)))\n",
    "wh['unigrams'] = wh['unigrams'].apply(lambda x: list(find_ngrams(x, 1)))\n",
    "# wh['key'] = wh['key'].apply(find_ngrams([word for word in wh['key']]) for word in x if word != \"\"])\n",
    "from collections import Counter\n",
    "bag_1 = Counter()\n",
    "for keywords in wh['unigrams']:\n",
    "    for keyword in keywords:\n",
    "        bag_1[keyword] += 1\n",
    "bag_remove = []\n",
    "for word in bag_1.most_common(500):\n",
    "    word = word[0]\n",
    "    if word.endswith('s'):\n",
    "        singular = word[:-1]\n",
    "        plural = word\n",
    "    else:\n",
    "        singular = word\n",
    "        plural = word + 's'\n",
    "    if bag_1[plural] >= bag_1[singular]:\n",
    "        bag_1[plural] += bag_1[singular]\n",
    "        bag_remove.append(singular)\n",
    "        wh['unigrams'] = wh['unigrams'].apply(lambda x: [plural if unigram == singular else unigram for unigram in x])\n",
    "    else:\n",
    "        bag_1[singular] += bag_1[plural]\n",
    "        bag_remove.append(plural)\n",
    "        wh['unigrams'] = wh['unigrams'].apply(lambda x: [singular if unigram == plural else unigram for unigram in x])\n",
    "for removal in bag_remove:\n",
    "    del bag_1[removal]\n",
    "bag_2 = Counter()\n",
    "for keywords in wh['bigrams']:\n",
    "    for keyword in keywords:\n",
    "        bag_2[keyword] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'is_noun'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-48ccf3b9b330>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_noun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'is_noun'"
     ]
    }
   ],
   "source": [
    "nltk.is_noun(\"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.3\n",
    "for bigram in bag_2.most_common(1000):\n",
    "    # print(\"{}: {}\".format(bigram[0][0], bag_1[bigram[0][0]] * 0.75))\n",
    "    if (bag_1[bigram[0][0]] * THRESHOLD) <= bag_2[bigram[0]]:\n",
    "        del bag_1[bigram[0][0]]\n",
    "        if (bag_1[bigram[0][1]] * THRESHOLD) <= bag_2[bigram[0]]:\n",
    "            del bag_1[bigram[0][1]]\n",
    "    else:\n",
    "        del bag_2[bigram[0]]\n",
    "print(bag_1[('video',)])\n",
    "wh['ngrams'] = wh['unigrams'] + wh['bigrams']\n",
    "bag_1_2 = (bag_1 + bag_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "wh['time'] = wh['time'].apply(lambda x: dt.datetime.strptime(x.split('T')[0], '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "def avg_datetime(series):\n",
    "    dt_min = series.min()\n",
    "    deltas = [(x - dt_min).days for x in series]\n",
    "    if len(deltas) == 0:\n",
    "        print(series)\n",
    "    return dt_min + timedelta(functools.reduce(operator.add, deltas) // len(deltas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_datetime(series):\n",
    "    dt_min = series.min()\n",
    "    deltas = [(x - dt_min).days for x in series]\n",
    "    return dt_min + timedelta(days = deltas[len(deltas)//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Series([], Name: keyword, dtype: object)\n",
      "0\n",
      "Series([], Name: keyword, dtype: object)\n",
      "1\n",
      "157    ukulele\n",
      "Name: keyword, dtype: object\n",
      "0\n",
      "Series([], Name: keyword, dtype: object)\n",
      "2\n",
      "189    failarmy\n",
      "303        2013\n",
      "Name: keyword, dtype: object\n",
      "4\n",
      "48       360\n",
      "171     2014\n",
      "174    fails\n",
      "176    remix\n",
      "Name: keyword, dtype: object\n",
      "5\n",
      "27             hd\n",
      "35     university\n",
      "58     comparison\n",
      "154         gopro\n",
      "243     minecraft\n",
      "Name: keyword, dtype: object\n",
      "12\n",
      "46          halo\n",
      "66         sound\n",
      "97        comedy\n",
      "99         lapse\n",
      "135      todoist\n",
      "147        funny\n",
      "194         baby\n",
      "199      android\n",
      "217    trailer 1\n",
      "258         play\n",
      "262         2012\n",
      "313       speech\n",
      "Name: keyword, dtype: object\n",
      "9\n",
      "31         seconds\n",
      "36            free\n",
      "44           cover\n",
      "73            face\n",
      "76          action\n",
      "153        warwick\n",
      "169    compilation\n",
      "187        episode\n",
      "240       ultimate\n",
      "Name: keyword, dtype: object\n",
      "25\n",
      "4             epic\n",
      "10           super\n",
      "18            game\n",
      "19           crazy\n",
      "32               r\n",
      "55       animation\n",
      "65            kids\n",
      "84           fight\n",
      "85            2015\n",
      "107          black\n",
      "117    numberphile\n",
      "125             de\n",
      "168          album\n",
      "178            big\n",
      "193           girl\n",
      "201             ad\n",
      "205           fire\n",
      "234            dog\n",
      "246          space\n",
      "252        version\n",
      "266           turn\n",
      "272         little\n",
      "300        example\n",
      "312          crash\n",
      "317         camera\n",
      "Name: keyword, dtype: object\n",
      "34\n",
      "8         review\n",
      "9           test\n",
      "13             w\n",
      "16          less\n",
      "24          real\n",
      "25           one\n",
      "50         night\n",
      "53         world\n",
      "64         white\n",
      "93          help\n",
      "100       police\n",
      "101          see\n",
      "108       street\n",
      "128          guy\n",
      "129          old\n",
      "132          sex\n",
      "133          car\n",
      "148          cat\n",
      "151       iphone\n",
      "155          mix\n",
      "160        right\n",
      "165         star\n",
      "177        scene\n",
      "190        dance\n",
      "223    algorithm\n",
      "225          red\n",
      "231        first\n",
      "233         full\n",
      "260     original\n",
      "275         slow\n",
      "278         ever\n",
      "286      moments\n",
      "311          man\n",
      "314          bad\n",
      "Name: keyword, dtype: object\n",
      "36\n",
      "2            part 1\n",
      "12          student\n",
      "17         festival\n",
      "43         pictures\n",
      "54             show\n",
      "56             demo\n",
      "71         overwerk\n",
      "78           online\n",
      "98            watch\n",
      "109          change\n",
      "124           youre\n",
      "145          tricks\n",
      "146        williams\n",
      "150       timelapse\n",
      "197      trailer hd\n",
      "198           house\n",
      "200         without\n",
      "230           speed\n",
      "232             run\n",
      "238              vs\n",
      "244           wrong\n",
      "248            open\n",
      "250          friend\n",
      "255            ball\n",
      "256           chris\n",
      "259    relationship\n",
      "270         amazing\n",
      "279            last\n",
      "282            good\n",
      "289            easy\n",
      "290         america\n",
      "301         history\n",
      "304             cut\n",
      "310            high\n",
      "315            love\n",
      "316           short\n",
      "Name: keyword, dtype: object\n",
      "50\n",
      "0            james\n",
      "28             end\n",
      "39           never\n",
      "41            stop\n",
      "45           break\n",
      "51     documentary\n",
      "57              uk\n",
      "61            mind\n",
      "62           light\n",
      "70            john\n",
      "74             art\n",
      "86            tips\n",
      "89            lets\n",
      "103         things\n",
      "110           time\n",
      "111           room\n",
      "112      christmas\n",
      "113            fat\n",
      "114         inside\n",
      "123       training\n",
      "134             la\n",
      "142             us\n",
      "152         system\n",
      "156           take\n",
      "158           week\n",
      "159         attack\n",
      "163         secret\n",
      "182           film\n",
      "183          women\n",
      "186           cant\n",
      "204        project\n",
      "210             go\n",
      "214         basics\n",
      "216        wedding\n",
      "221       tutorial\n",
      "224         making\n",
      "226           lost\n",
      "228             ep\n",
      "236     girlfriend\n",
      "239      challenge\n",
      "241           song\n",
      "242          hacks\n",
      "247              c\n",
      "271        problem\n",
      "276            fix\n",
      "281            100\n",
      "291            get\n",
      "306         series\n",
      "308          story\n",
      "318         season\n",
      "Name: keyword, dtype: object\n",
      "42\n",
      "11            minutes\n",
      "21            youtube\n",
      "22               date\n",
      "23             update\n",
      "29               jack\n",
      "30                may\n",
      "34     teaser trailer\n",
      "38               back\n",
      "42               dont\n",
      "52               2016\n",
      "63            getting\n",
      "81                men\n",
      "83               tour\n",
      "87             create\n",
      "92             lyrics\n",
      "105    official audio\n",
      "116              like\n",
      "118       introducing\n",
      "120              life\n",
      "126             great\n",
      "131         interview\n",
      "136              talk\n",
      "143             guide\n",
      "144             truth\n",
      "149              live\n",
      "167            habits\n",
      "181              want\n",
      "202               way\n",
      "203             woman\n",
      "208              made\n",
      "212              edit\n",
      "220              look\n",
      "229              need\n",
      "235               got\n",
      "249                im\n",
      "253          crossfit\n",
      "257            coffee\n",
      "264            people\n",
      "274       lyric video\n",
      "288             final\n",
      "302             party\n",
      "305                 x\n",
      "Name: keyword, dtype: object\n",
      "32\n",
      "3          programming\n",
      "26             healthy\n",
      "40              future\n",
      "49              become\n",
      "59            actually\n",
      "80             science\n",
      "82                work\n",
      "91              london\n",
      "96               using\n",
      "115               food\n",
      "122               home\n",
      "141                job\n",
      "161               meet\n",
      "162                day\n",
      "164             summer\n",
      "166               road\n",
      "172                app\n",
      "184               vlog\n",
      "188              whats\n",
      "192             dating\n",
      "195             really\n",
      "211            fitness\n",
      "227               year\n",
      "261       introduction\n",
      "265               data\n",
      "267             google\n",
      "269              learn\n",
      "273               dark\n",
      "287                two\n",
      "292         experience\n",
      "299               know\n",
      "322    morning routine\n",
      "Name: keyword, dtype: object\n",
      "28\n",
      "5            netflix\n",
      "20     hannah witton\n",
      "33            simple\n",
      "47          happened\n",
      "60             money\n",
      "72              2017\n",
      "75            eating\n",
      "79          bbc news\n",
      "121             away\n",
      "137        every day\n",
      "138           design\n",
      "140            hours\n",
      "170          pixel 2\n",
      "179           better\n",
      "196                –\n",
      "207           advice\n",
      "213             milk\n",
      "218             book\n",
      "251        questions\n",
      "254        beginners\n",
      "277              use\n",
      "283              web\n",
      "284               ai\n",
      "285            phone\n",
      "298           tinder\n",
      "307            place\n",
      "319            trump\n",
      "320         mistakes\n",
      "Name: keyword, dtype: object\n",
      "12\n",
      "1      body transformation\n",
      "14                    left\n",
      "69            social media\n",
      "88                   going\n",
      "175             minimalist\n",
      "180               coldplay\n",
      "185                   side\n",
      "206                workout\n",
      "219              pronounce\n",
      "295                      »\n",
      "296                started\n",
      "309                  apple\n",
      "Name: keyword, dtype: object\n",
      "15\n",
      "6             thenx\n",
      "7                qa\n",
      "15          control\n",
      "37            vegan\n",
      "68       minimalism\n",
      "90         building\n",
      "94         tracking\n",
      "104          living\n",
      "106        software\n",
      "127         ansible\n",
      "191             vim\n",
      "215       instagram\n",
      "237          python\n",
      "263    calisthenics\n",
      "297    inbetweeners\n",
      "Name: keyword, dtype: object\n",
      "4\n",
      "119        developer\n",
      "130             2018\n",
      "139    glass animals\n",
      "222             code\n",
      "Name: keyword, dtype: object\n",
      "3\n",
      "102         flutter\n",
      "173         stretch\n",
      "245    react native\n",
      "Name: keyword, dtype: object\n",
      "2\n",
      "67    brexit explained\n",
      "77                2019\n",
      "Name: keyword, dtype: object\n",
      "0\n",
      "Series([], Name: keyword, dtype: object)\n",
      "0\n",
      "Series([], Name: keyword, dtype: object)\n",
      "0\n",
      "Series([], Name: keyword, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import random\n",
    "import math\n",
    "from plotly import colors\n",
    "\n",
    "NUM_KEYWORDS = 350\n",
    "palette = ['darkturquoise', 'darkorange', 'darkorchid', 'mediumseagreen', 'royalblue', 'saddlebrown', 'tomato']\n",
    "plotly_colors = [palette[random.randrange(0, len(palette))] for i in range(NUM_KEYWORDS)]\n",
    "\n",
    "# group_labels = ['minecraft', 'calisthenics', 'sex', 'dating', 'brexit', 'fail', 'minimalist', 'compilation', 'london', 'vegan', 'world', 'trump', 'tinder', 'react', 'flutter', 'summer', 'gopro']\n",
    "removals = [\"video\", \"trailer\", \"new\", \"best\", \"official\", \"removed\", \"music\", \"ft\", \"feat\"] + [str(x) for x in list(range(100))]\n",
    "removals += [(\"official\",  \"video\"), (\"official\", \"trailer\"), (\"music\", \"video\"), (\"official\", \"music\")]\n",
    "group_labels = list(set([x[0] for x in bag_1_2.most_common(NUM_KEYWORDS)]) - set(removals))\n",
    "data = pd.DataFrame([], columns=[\"keyword\", \"x\", \"y\", \"freq\"])\n",
    "for keyword in group_labels:\n",
    "    dates = wh[wh['ngrams'].apply(lambda x: (True if keyword in x else False))]['time']\n",
    "    data = data.append({\n",
    "        \"keyword\": keyword if isinstance(keyword, str) else \" \".join(keyword) ,\n",
    "        \"x\": avg_datetime(dates),\n",
    "        \"y\": 0,\n",
    "        \"freq\": len(dates)\n",
    "    }, ignore_index=True)\n",
    "import numpy as np\n",
    "for year in [2014, 2015, 2016, 2017, 2018, 2019]:\n",
    "    for month in [1, 4, 7, 10]:\n",
    "        selected_year = data['x'].apply(lambda x: (True if datetime(year, month, 1) < x <= datetime(year, month, 1) + timedelta(days=90) else False))\n",
    "        num_selected = len(data[selected_year == True])\n",
    "        print(num_selected)\n",
    "        print(data[selected_year]['keyword'])\n",
    "        ys = [x + 1/(num_selected + 1) + random.uniform(-0.02, +0.02) for x in np.linspace(0,1,num_selected+2)][:-2]\n",
    "        random.shuffle(ys)\n",
    "        data.loc[selected_year, 'y'] = ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programming</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>0.818949</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>part 1</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>0.091583</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netflix</td>\n",
       "      <td>2018-06-18</td>\n",
       "      <td>0.304779</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review</td>\n",
       "      <td>2016-10-16</td>\n",
       "      <td>0.738069</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>2016-11-20</td>\n",
       "      <td>0.245195</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>student</td>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>0.419609</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>v</td>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>0.230701</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>game</td>\n",
       "      <td>2016-03-24</td>\n",
       "      <td>0.323794</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>youtube</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0.634769</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>crazy</td>\n",
       "      <td>2016-10-21</td>\n",
       "      <td>0.511947</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>update</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>0.059328</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>one</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0.449821</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>real</td>\n",
       "      <td>2017-04-11</td>\n",
       "      <td>0.894928</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hd</td>\n",
       "      <td>2014-12-16</td>\n",
       "      <td>0.154220</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>end</td>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>0.515324</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>may</td>\n",
       "      <td>2017-09-27</td>\n",
       "      <td>0.546187</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>simple</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>0.689617</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>university</td>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>0.872498</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>free</td>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>0.267738</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vegan</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>0.594002</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>back</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>0.063971</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>never</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>0.660056</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dont</td>\n",
       "      <td>2017-09-14</td>\n",
       "      <td>0.491655</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stop</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>halo</td>\n",
       "      <td>2015-03-27</td>\n",
       "      <td>0.672857</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>night</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>0.816463</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>0.037393</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>world</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>0.654261</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>show</td>\n",
       "      <td>2017-05-07</td>\n",
       "      <td>0.778609</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>make</td>\n",
       "      <td>2018-01-27</td>\n",
       "      <td>0.738657</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>data</td>\n",
       "      <td>2018-03-20</td>\n",
       "      <td>0.509471</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>google</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>0.759208</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>learn</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>0.772403</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>problem</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>0.446205</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>lyric video</td>\n",
       "      <td>2018-02-06</td>\n",
       "      <td>0.199491</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ever</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>0.136052</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>use</td>\n",
       "      <td>2018-04-30</td>\n",
       "      <td>0.362847</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>last</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>0.165601</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>movie hd</td>\n",
       "      <td>2014-11-21</td>\n",
       "      <td>0.663797</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>good</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>two</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>0.399376</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>easy</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>0.409187</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>get</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>0.906923</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>tv</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>0.514004</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>»</td>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>0.895699</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>know</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tinder</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>0.703909</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2013</td>\n",
       "      <td>2014-05-28</td>\n",
       "      <td>0.517996</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>x</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>0.140239</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>high</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>0.362387</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>story</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>0.299045</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>camera</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>0.504378</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>short</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>0.596725</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>man</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>0.128974</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>crash</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>0.482932</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>love</td>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>0.255750</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>bad</td>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>0.833434</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>trump</td>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>0.766615</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>relationship</td>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>0.205674</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword          x         y freq\n",
       "0     programming 2017-08-22  0.818949   34\n",
       "1          part 1 2017-05-04  0.091583   40\n",
       "2         netflix 2018-06-18  0.304779   45\n",
       "3          review 2016-10-16  0.738069   78\n",
       "4            test 2016-11-20  0.245195   35\n",
       "5         student 2017-08-24  0.419609   33\n",
       "6               v 2017-07-07  0.230701  168\n",
       "7            game 2016-03-24  0.323794   63\n",
       "8         youtube 2017-08-02  0.634769   37\n",
       "9            date 2018-01-01  0.000000   29\n",
       "10          crazy 2016-10-21  0.511947   28\n",
       "11         update 2017-08-01  0.059328   28\n",
       "12            one 2017-04-23  0.449821  104\n",
       "13           real 2017-04-11  0.894928   46\n",
       "14             hd 2014-12-16  0.154220  187\n",
       "15            end 2018-02-11  0.515324   28\n",
       "16            may 2017-09-27  0.546187   38\n",
       "17         simple 2018-04-06  0.689617   34\n",
       "18     university 2015-08-05  0.872498   27\n",
       "19           free 2015-09-23  0.267738   40\n",
       "20          vegan 2018-05-26  0.594002   92\n",
       "21           back 2017-12-14  0.063971   40\n",
       "22          never 2017-09-29  0.660056   31\n",
       "23           dont 2017-09-14  0.491655   58\n",
       "24           stop 2017-08-22  0.969881   35\n",
       "25           halo 2015-03-27  0.672857   54\n",
       "26          night 2017-03-11  0.816463   52\n",
       "27           2016 2017-04-30  0.037393   46\n",
       "28          world 2017-04-23  0.654261   95\n",
       "29           show 2017-05-07  0.778609   41\n",
       "..            ...        ...       ...  ...\n",
       "146          make 2018-01-27  0.738657   82\n",
       "147          data 2018-03-20  0.509471   38\n",
       "148        google 2017-10-27  0.759208   98\n",
       "149         learn 2018-02-13  0.772403   29\n",
       "150       problem 2017-07-17  0.446205   32\n",
       "151   lyric video 2018-02-06  0.199491   30\n",
       "152          ever 2017-03-20  0.136052   59\n",
       "153           use 2018-04-30  0.362847   35\n",
       "154          last 2017-05-25  0.165601   39\n",
       "155      movie hd 2014-11-21  0.663797   53\n",
       "156          good 2017-07-01  0.000000   38\n",
       "157           two 2018-02-08  0.399376   31\n",
       "158          easy 2017-01-31  0.409187   32\n",
       "159           get 2017-09-29  0.906923   98\n",
       "160            tv 2015-12-06  0.514004   32\n",
       "161             » 2018-02-07  0.895699   31\n",
       "162          know 2018-02-13  0.012205   62\n",
       "163        tinder 2017-11-11  0.703909   37\n",
       "164          2013 2014-05-28  0.517996   75\n",
       "165             x 2017-11-11  0.140239   31\n",
       "166          high 2017-10-21  0.362387   32\n",
       "167         story 2017-08-22  0.299045   42\n",
       "168        camera 2015-07-23  0.504378   34\n",
       "169         short 2017-03-11  0.596725   33\n",
       "170           man 2017-04-21  0.128974   61\n",
       "171         crash 2016-05-15  0.482932   29\n",
       "172          love 2017-06-05  0.255750   80\n",
       "173           bad 2016-03-21  0.833434   44\n",
       "174         trump 2018-02-04  0.766615   43\n",
       "175  relationship 2017-08-02  0.205674   27\n",
       "\n",
       "[176 rows x 4 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot\n",
    "trace = go.Scatter(\n",
    "    x = data[\"x\"],\n",
    "    y = data[\"y\"],\n",
    "    mode = \"text\",\n",
    "    text = [x.upper() for x in data[\"keyword\"]],\n",
    "    opacity=0.75,\n",
    "    textfont={\n",
    "        'size': [x // 3.5 for x in list(data[\"freq\"])],\n",
    "        'color': plotly_colors,\n",
    "        'family': 'Roboto'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace]\n",
    "py.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99428571, 0.04      , 0.15428571, 0.41714286, 0.02285714,\n",
       "       0.50285714, 0.12      , 0.36      , 0.95428571, 0.42857143,\n",
       "       0.33714286, 0.89714286, 0.56571429, 0.53142857, 0.2       ,\n",
       "       0.54285714, 0.74857143, 0.55428571, 0.94857143, 0.58857143,\n",
       "       0.04571429, 0.56      , 0.79428571, 0.35428571, 0.34285714,\n",
       "       0.16      , 0.24      , 0.93142857, 0.72      , 0.02857143,\n",
       "       0.69142857, 0.45714286, 0.68571429, 0.90285714, 0.49142857,\n",
       "       0.83428571, 0.98285714, 0.08      , 0.87428571, 0.44571429,\n",
       "       0.64      , 0.00571429, 0.76571429, 0.43428571, 0.98857143,\n",
       "       0.77142857, 0.72571429, 0.65714286, 0.10857143, 0.29142857,\n",
       "       0.14285714, 0.88      , 0.21142857, 0.70857143, 0.65142857,\n",
       "       0.84      , 0.53714286, 0.90857143, 0.61142857, 0.86857143,\n",
       "       0.40571429, 0.66285714, 0.28      , 0.38285714, 0.11428571,\n",
       "       0.85714286, 0.4       , 0.16571429, 0.25142857, 0.96571429,\n",
       "       0.91428571, 0.30857143, 0.57142857, 0.76      , 0.82857143,\n",
       "       0.75428571, 0.21714286, 0.10285714, 0.52571429, 0.51428571,\n",
       "       0.69714286, 0.81714286, 0.63428571, 0.09142857, 0.03428571,\n",
       "       0.80571429, 0.38857143, 0.18857143, 0.48      , 0.74285714,\n",
       "       0.06285714, 0.22857143, 0.17714286, 0.25714286, 0.50857143,\n",
       "       0.36571429, 0.22285714, 0.73714286, 0.67428571, 0.78285714,\n",
       "       0.47428571, 0.06857143, 0.34857143, 0.84571429, 0.48571429,\n",
       "       0.70285714, 0.01714286, 0.85142857, 0.13142857, 0.86285714,\n",
       "       0.93714286, 0.23428571, 0.61714286, 0.09714286, 0.62857143,\n",
       "       0.13714286, 0.66857143, 0.27428571, 0.59428571, 0.78857143,\n",
       "       0.14857143, 0.24571429, 0.92      , 0.29714286, 0.8       ,\n",
       "       0.33142857, 0.18285714, 0.71428571, 0.26857143, 0.46857143,\n",
       "       0.81142857, 1.        , 0.58285714, 0.31428571, 0.52      ,\n",
       "       0.41142857, 0.45142857, 0.44      , 0.68      , 0.64571429,\n",
       "       0.6       , 0.73142857, 0.94285714, 0.05714286, 0.97714286,\n",
       "       0.19428571, 0.49714286, 0.28571429, 0.88571429, 0.92571429,\n",
       "       0.54857143, 0.96      , 0.89142857, 0.01142857, 0.97142857,\n",
       "       0.05142857, 0.57714286, 0.        , 0.62285714, 0.12571429,\n",
       "       0.30285714, 0.77714286, 0.60571429, 0.20571429, 0.82285714,\n",
       "       0.37142857, 0.37714286, 0.08571429, 0.42285714, 0.26285714,\n",
       "       0.46285714, 0.39428571, 0.07428571, 0.17142857, 0.32      ,\n",
       "       0.32571429])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "59\n",
      "86\n",
      "15\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for year in [2015, 2016, 2017, 2018, 2019]:\n",
    "    selected_year = data['x'].apply(lambda x: (True if datetime(year, 1, 1) < x < datetime(year+1, 1, 1) else False))\n",
    "    num_selected = len(data[selected_year == True])\n",
    "    ys = np.linspace(0,1,num_selected)\n",
    "    random.shuffle(ys)\n",
    "    print(num_selected)\n",
    "    data.loc[selected_year, 'y'] = ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>programming</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>0.869552</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>part 1</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netflix</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>0.991760</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thenx</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>0.735074</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>review</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>minutes</td>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>0.418962</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>game</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>0.568966</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>youtube</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>0.221309</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>crazy</td>\n",
       "      <td>2016-06-22</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>update</td>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>0.991802</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>date</td>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>0.346060</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>one</td>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>0.293103</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>real</td>\n",
       "      <td>2016-08-20</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>healthy</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>0.771415</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hd</td>\n",
       "      <td>2015-09-25</td>\n",
       "      <td>0.267607</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>end</td>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>0.731069</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>may</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>simple</td>\n",
       "      <td>2017-10-15</td>\n",
       "      <td>0.950105</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>university</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>0.292044</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>free</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vegan</td>\n",
       "      <td>2018-05-11</td>\n",
       "      <td>0.438634</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>back</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>0.290725</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>never</td>\n",
       "      <td>2017-02-04</td>\n",
       "      <td>0.765104</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dont</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>0.510103</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stop</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.293686</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>halo</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>0.672537</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>night</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>0.652718</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>world</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>calisthenics</td>\n",
       "      <td>2018-06-11</td>\n",
       "      <td>0.955747</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>make</td>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>0.628033</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>data</td>\n",
       "      <td>2017-09-26</td>\n",
       "      <td>0.898609</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>google</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>0.410072</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>learn</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>0.168709</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>problem</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>0.034508</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>lyric video</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>0.669905</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>ever</td>\n",
       "      <td>2016-08-22</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>use</td>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>0.015631</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>last</td>\n",
       "      <td>2016-11-10</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>movie hd</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>0.714921</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>good</td>\n",
       "      <td>2016-11-21</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>two</td>\n",
       "      <td>2017-09-20</td>\n",
       "      <td>0.862063</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>easy</td>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>get</td>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>0.505417</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tv</td>\n",
       "      <td>2016-02-10</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>»</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>0.569264</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>know</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0.160307</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>tinder</td>\n",
       "      <td>2017-10-30</td>\n",
       "      <td>0.029135</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>days</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>0.601607</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2013</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>0.103349</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>x</td>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>0.134728</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>high</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>story</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>0.293318</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>camera</td>\n",
       "      <td>2016-05-10</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>man</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>crash</td>\n",
       "      <td>2016-06-10</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>love</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>bad</td>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>trump</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>0.359921</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          keyword          x         y freq\n",
       "0     programming 2017-08-16  0.869552   34\n",
       "1          part 1 2016-12-23  0.344828   40\n",
       "2         netflix 2017-10-18  0.991760   44\n",
       "3           thenx 2018-05-22  0.735074   26\n",
       "4          review 2016-05-21  0.706897   73\n",
       "5            test 2016-07-05  0.982759   33\n",
       "6         minutes 2017-06-06  0.418962   56\n",
       "7            game 2016-06-27  0.568966   53\n",
       "8         youtube 2017-05-20  0.221309   36\n",
       "9           crazy 2016-06-22  0.500000   28\n",
       "10         update 2017-05-03  0.991802   28\n",
       "11           date 2017-01-25  0.346060   25\n",
       "12            one 2016-08-11  0.293103  101\n",
       "13           real 2016-08-20  0.189655   46\n",
       "14        healthy 2017-08-23  0.771415   25\n",
       "15             hd 2015-09-25  0.267607  187\n",
       "16            end 2017-01-23  0.731069   27\n",
       "17            may 2016-11-02  0.051724   27\n",
       "18         simple 2017-10-15  0.950105   34\n",
       "19     university 2015-09-27  0.292044   27\n",
       "20           free 2016-03-30  0.655172   40\n",
       "21          vegan 2018-05-11  0.438634   90\n",
       "22           back 2017-06-20  0.290725   40\n",
       "23          never 2017-02-04  0.765104   31\n",
       "24           dont 2017-05-31  0.510103   55\n",
       "25           stop 2017-03-01  0.293686   34\n",
       "26           halo 2015-12-10  0.672537   54\n",
       "27          night 2016-08-14  0.017241   49\n",
       "28           2016 2017-04-27  0.652718   46\n",
       "29          world 2016-07-01  0.879310   80\n",
       "..            ...        ...       ...  ...\n",
       "146  calisthenics 2018-06-11  0.955747   45\n",
       "147          make 2017-07-28  0.628033   69\n",
       "148          data 2017-09-26  0.898609   38\n",
       "149        google 2017-08-07  0.410072   93\n",
       "150         learn 2017-08-18  0.168709   27\n",
       "151       problem 2017-02-13  0.034508   29\n",
       "152   lyric video 2017-06-19  0.669905   30\n",
       "153          ever 2016-08-22  0.793103   59\n",
       "154           use 2017-10-11  0.015631   32\n",
       "155          last 2016-11-10  0.862069   39\n",
       "156      movie hd 2015-09-30  0.714921   53\n",
       "157          good 2016-11-21  0.482759   38\n",
       "158           two 2017-09-20  0.862063   31\n",
       "159          easy 2016-10-13  0.741379   32\n",
       "160           get 2017-05-13  0.505417   72\n",
       "161            tv 2016-02-10  0.155172   30\n",
       "162             » 2018-01-16  0.569264   31\n",
       "163          know 2017-08-27  0.160307   56\n",
       "164        tinder 2017-10-30  0.029135   37\n",
       "165          days 2017-12-16  0.601607   40\n",
       "166          2013 2015-01-30  0.103349   74\n",
       "167             x 2017-06-05  0.134728   31\n",
       "168          high 2016-10-19  0.465517   31\n",
       "169         story 2017-02-13  0.293318   42\n",
       "170        camera 2016-05-10  0.396552   33\n",
       "171           man 2016-09-17  0.137931   59\n",
       "172         crash 2016-06-10  0.724138   29\n",
       "173          love 2016-10-25  0.206897   77\n",
       "174           bad 2016-07-13  0.948276   44\n",
       "175         trump 2017-11-22  0.359921   38\n",
       "\n",
       "[176 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# generate some random data (approximately over 5 years)\n",
    "\n",
    "# convert the epoch format to matplotlib date format \n",
    "mpl_data = wh['time']\n",
    "\n",
    "# plot it\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(mpl_data, bins=100, color='lightblue')\n",
    "locator = mdates.AutoDateLocator()\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(locator))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyword = \"date\"\n",
    "wh['freq'] = wh['key'].apply(lambda x: 1 if keyword in x else 0)\n",
    "\n",
    "wh[wh['freq'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "bag = Counter()\n",
    "for keywords in wh['key']:\n",
    "    for keyword in keywords:\n",
    "        bag[keyword] += 1\n",
    "#     for i in range(len(keywords)-1):\n",
    "#         bag[\" \".join(keywords[i:i+2])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x0 = np.random.randn(500)\n",
    "x1 = np.random.randn(500)+1\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=x0,\n",
    "    opacity=0.75\n",
    ")\n",
    "trace2 = go.Histogram(\n",
    "    x=x1,\n",
    "    opacity=0.75\n",
    ")\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(barmode='overlay')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.init_notebook_mode(connected=True)\n",
    "py.iplot(fig, filename='overlaid histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "data = []\n",
    "\n",
    "def to_unix_time(datet):\n",
    "    epoch =  dt.datetime.utcfromtimestamp(0)\n",
    "    return (datet - epoch).total_seconds() * 1000\n",
    "\n",
    "group_labels = ['minecraft', 'calisthenics', 'sex', 'dating', 'brexit', 'fail', 'minimalist', 'compilation', 'london', 'vegan', 'world', 'trump', 'tinder', 'react', 'flutter', 'summer', 'gopro']\n",
    "# group_labels = ['calisthenics', 'workout', 'vegan', 'dating', 'minimalist', 'mimalism', 'vegetarian']\n",
    "\n",
    "# group_labels = [x for x,_ in bag.most_common(10)]\n",
    "print(group_labels)\n",
    "hist_data = []\n",
    "\n",
    "for keyword in group_labels:\n",
    "    print(keyword)\n",
    "    data.append(\n",
    "        go.Histogram(\n",
    "            x=wh[wh['key'].apply(lambda x: (True if keyword in x else False))]['time'],\n",
    "            xbins=dict(\n",
    "                    start=dt.datetime(2013, 1, 1),\n",
    "                    end=dt.datetime(2018, 12, 31),\n",
    "                    size=(to_unix_time(dt.datetime(2019, 4, 1))-to_unix_time(dt.datetime(2019, 1, 1)))\n",
    "                ),\n",
    "            name=keyword,\n",
    "            opacity=0.75\n",
    "        )\n",
    "    )\n",
    "\n",
    "layout = go.Layout(barmode='stack')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.init_notebook_mode(connected=True)\n",
    "py.iplot(fig, filename='overlaid histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "data = []\n",
    "\n",
    "def to_unix_time(datet):\n",
    "    epoch =  dt.datetime.utcfromtimestamp(0)\n",
    "    return (datet - epoch).total_seconds() * 1000\n",
    "\n",
    "group_labels = ['minecraft', 'calisthenics', 'sex', 'dating', 'brexit', 'fail', 'minimalist', 'compilation', 'london', 'vegan', 'world', 'trump', 'tinder', 'react', 'flutter', 'summer', 'gopro']\n",
    "# group_labels = ['calisthenics', 'workout', 'vegan', 'dating', 'minimalist', 'mimalism', 'vegetarian']\n",
    "\n",
    "# group_labels = [x for x,_ in bag.most_common(10)]\n",
    "print(group_labels)\n",
    "hist_data = []\n",
    "\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x = wh[wh['key'].apply(lambda x: (True if keyword in x else False))]['time'],\n",
    "    y = random.sample(rang(0, 1), len(x))\n",
    "    \n",
    ")\n",
    "\n",
    "for keyword in group_labels:\n",
    "    data.append(\n",
    "        go.Histogram(\n",
    "            x=wh[wh['key'].apply(lambda x: (True if keyword in x else False))]['time'],\n",
    "            xbins=dict(\n",
    "                    start=dt.datetime(2013, 1, 1),\n",
    "                    end=dt.datetime(2018, 12, 31),\n",
    "                    size=(to_unix_time(dt.datetime(2019, 4, 1))-to_unix_time(dt.datetime(2019, 1, 1)))\n",
    "                ),\n",
    "            name=keyword,\n",
    "            opacity=0.75\n",
    "        )\n",
    "    )\n",
    "\n",
    "layout = go.Layout(barmode='stack')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.init_notebook_mode(connected=True)\n",
    "py.iplot(fig, filename='overlaid histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import numpy as np\n",
    "# group_labels = ['minecraft', 'calisthenics', 'sex', 'dating', 'brexit', 'fail', 'minimalist', 'compilation', 'london', 'vegan', 'world', 'trump', 'tinder', 'react', 'flutter', 'summer', 'gopro']\n",
    "group_labels = ['flutter', 'android', 'react', 'python', 'java']\n",
    "hist_data=[]\n",
    "for keyword in group_labels:\n",
    "    hist_data.append(wh[wh['key'].apply(lambda x: (True if keyword in x else False))]['time'].apply(lambda x: 1970 + (to_unix_time(x))/31536000000))\n",
    "\n",
    "# Create distplot with curve_type set to 'normal'\n",
    "fig = ff.create_distplot(hist_data, group_labels, show_hist=False)\n",
    "\n",
    "# Add title\n",
    "fig['layout'].update(title='Curve and Rug Plot')\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Curve and Rug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "# Group data together\n",
    "group_labels = [x for x,_ in bag.most_common(10)]\n",
    "hist_data = []\n",
    "for keyword in group_labels:\n",
    "    reply_list = list(wh[wh['key'].apply(lambda x: (True if keyword in x else False))]['time'])\n",
    "    reply_list = [to_unix_time(x) for x in reply_list]\n",
    "    hist_data.append(reply_list)\n",
    "\n",
    "    \n",
    "    \n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels)\n",
    "\n",
    "# Plot!\n",
    "py.iplot(fig, filename='Distplot with Multiple Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# bins = np.arange(datetime(2013, 1, 1), datetime(2019, 1, 1), timedelta(days=30)).astype(datetime)\n",
    "bins = np.linspace(0, 360, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "# generate some random data (approximately over 5 years)\n",
    "\n",
    "# convert the epoch format to matplotlib date format \n",
    "mpl_data = wh[wh['freq'] == 1]['time']\n",
    "\n",
    "\n",
    "# plot it\n",
    "fig, ax = plt.subplots(1,1)\n",
    "for keyword in ['london', 'calisthenics', 'fails']:\n",
    "    mpl_data = wh[wh['key'].apply(lambda x: (True if keyword in x else False))]['time']\n",
    "    ax.hist(mpl_data, bins=50, alpha=0.5, label=keyword)\n",
    "locator = mdates.AutoDateLocator()\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(locator))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wh[wh['key'].apply(lambda x: (True if 'halo' in x else False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def levenshtein(seq1, seq2):  \n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "list_words = [x for x,_ in bag.most_common(200)]\n",
    "for a,b in itertools.product(list_words, repeat=2):\n",
    "    ld = levenshtein(a, b)\n",
    "    if ld != 0 and ld < 3:\n",
    "        print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1970 + (to_unix_time(dt.datetime(2019,1,1)))/31536000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "d['programming'] = ['flutter', 'react', 'python', 'code', 'ansible', 'programming', 'coding']\n",
    "d['diet'] = ['vegan', 'food', 'cooking', 'vegetarian']\n",
    "d['politics'] = ['trump', 'brexit']\n",
    "d['dating'] = ['date', 'dating', 'tinder', 'bumble', 'girlfriend']\n",
    "d['minimalism'] = ['minimalism', 'essentialism', 'minimalist']\n",
    "d['exercise'] = ['calisthenics', 'gym', 'freeletics', 'thenx']\n",
    "d['videogames'] = ['halo', 'minecraft', 'xbox', 'gameplay']\n",
    "d['compilations'] = ['compilation', 'fail', 'failarmy', 'fails']\n",
    "d['routines'] = ['routine', 'habits']\n",
    "for key, array in d.items():\n",
    "    print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "data = []\n",
    "\n",
    "def to_unix_time(datet):\n",
    "    epoch =  dt.datetime.utcfromtimestamp(0)\n",
    "    return (datet - epoch).total_seconds() * 1000\n",
    "\n",
    "group_labels = ['minecraft', 'calisthenics', 'sex', 'dating', 'brexit', 'fail', 'minimalist', 'compilation', 'london', 'vegan', 'world', 'trump', 'tinder', 'react', 'flutter', 'summer', 'gopro']\n",
    "# group_labels = ['calisthenics', 'workout', 'vegan', 'dating', 'minimalist', 'mimalism', 'vegetarian']\n",
    "\n",
    "# group_labels = [x for x,_ in bag.most_common(10)]\n",
    "print(group_labels)\n",
    "hist_data = []\n",
    "\n",
    "for key, array in d.items():\n",
    "    set_obj = set()\n",
    "    for idea in array:\n",
    "        set_obj = set_obj.union(wh[wh['key'].apply(lambda x: (True if idea in x else False))]['time'])\n",
    "    print(key)\n",
    "    data.append(\n",
    "        go.Histogram(\n",
    "            x=list(set_obj),\n",
    "            xbins=dict(\n",
    "                    start=dt.datetime(2013, 1, 1),\n",
    "                    end=dt.datetime(2018, 12, 31),\n",
    "                    size=(to_unix_time(dt.datetime(2019, 4, 1))-to_unix_time(dt.datetime(2019, 1, 1)))\n",
    "                ),\n",
    "            name=key,\n",
    "            opacity=0.75\\\n",
    "        )\n",
    "    )\n",
    "\n",
    "layout = go.Layout(barmode='stack')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.init_notebook_mode(connected=True)\n",
    "py.iplot(fig, filename='overlaid histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "tokens = nlp(u'dog cat banana afskfsd')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
